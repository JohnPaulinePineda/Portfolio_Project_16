---
title: "R : Evaluating Model-Independent Feature Importance for Predictors with Dichotomous Categorical Responses"
author: "John Pauline Pineda"
date: "December 14, 2022"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```
# **1. Table of Contents**
|
| This document presents a non-exhaustive list of feature importance metrics for predictors with dichotomous categorical responses using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>.  
|
| Model-independent feature importance determines the degree of relationship, usefulness and contribution of the independent variables (features) with respect to the dependent variables (target responses), outside the context of the particular model structure being applied. Analyzing the importance metrics of features allow the discovery and inclusion of only relevant features, reducing the number of meaningful variables in the model thereby providing more targeted insights into the data, speeding up the processing time, boosting its predictive performance and improving the interpretability of the results. The algorithms applied in this study (mostly contained in the <mark style="background-color: #CCECFF">**caret**</mark> package, <mark style="background-color: #CCECFF">**stats**</mark> package, <mark style="background-color: #CCECFF">**minerva**</mark> package and <mark style="background-color: #CCECFF">**CORElearn**</mark> packages) attempt to assign scores to input features based on their relevance at discriminating or predicting the target variable.
|
##  1.1 Sample Data
|
| The <mark style="background-color: #EEEEEE;color: #FF0000">**Solubility**</mark>  dataset from the  <mark style="background-color: #CCECFF">**AppliedPredictiveModeling**</mark> package was used for this illustrated example. The original numeric response was transformed to simulate a dichotomous categorical variable.
|
| Preliminary dataset assessment:
|
| **[A]** 1267 rows (observations)
|      **[A.1]** Train Set = 951 observations
|      **[A.2]** Test Set = 316 observations
| 
| **[B]** 229 columns (variables)
|      **[B.1]** 1/229 response = <span style="color: #FF0000">Log_Solubility_Class</span> variable (factor)
|             **[B.1.1]** Levels = <span style="color: #FF0000">Log_Solubility_Class=Low</span> < <span style="color: #FF0000">Log_Solubility_Class=High</span>
|      **[B.2]** 228/229 predictors = All remaining variables (208/228 factor + 20/228 numeric)
|     
| 
```{r section_1.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(AppliedPredictiveModeling)
library(caret)
library(rpart)
library(lattice)
library(dplyr)
library(tidyr)
library(moments)
library(skimr)
library(RANN)
library(pls)
library(corrplot)
library(tidyverse)
library(lares)
library(DMwR)
library(gridExtra)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(stats)
library(nnet)
library(elasticnet)
library(earth)
library(party)
library(kernlab)
library(randomForest)
library(Cubist)
library(pROC)
library(mda)
library(klaR)
library(pamr)
library(minerva)
library(CORElearn)

##################################
# Loading source and
# formulating the train set
##################################
data(solubility)
Solubility_Train <- as.data.frame(cbind(solTrainY,solTrainX))
Solubility_Test  <- as.data.frame(cbind(solTestY,solTestX))

##################################
# Applying dichotomization and
# defining the response variable
##################################
Solubility_Train$Log_Solubility_Class <- ifelse(Solubility_Train$solTrainY<mean(Solubility_Train$solTrainY),
                                                "Low","High")
Solubility_Train$Log_Solubility_Class <- factor(Solubility_Train$Log_Solubility_Class,
                                                levels = c("Low","High"))
Solubility_Test$Log_Solubility_Class <- ifelse(Solubility_Test$solTestY<mean(Solubility_Train$solTrainY),
                                                "Low","High")
Solubility_Test$Log_Solubility_Class <- factor(Solubility_Test$Log_Solubility_Class,
                                                levels = c("Low","High"))

Solubility_Train$solTrainY <- NULL
Solubility_Test$solTestY <- NULL

##################################
# Performing a general exploration of the train set
##################################
dim(Solubility_Train)
str(Solubility_Train)
summary(Solubility_Train)

##################################
# Performing a general exploration of the test set
##################################
dim(Solubility_Test)
str(Solubility_Test)
summary(Solubility_Test)

##################################
# Formulating a data type assessment summary
##################################
PDA <- Solubility_Train
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)
```
##  1.2 Data Quality Assessment
|
| Data quality assessment:
|
| **[A]** No missing observations noted for any variable.
|
| **[B]** Low variance observed for 127 variables with First.Second.Mode.Ratio>5.
|      **[B.1]-[B.33]** <span style="color: #FF0000">FP013</span> to <span style="color: #FF0000">FP045</span> variables (factor)
|      **[B.34]-[B.45]** <span style="color: #FF0000">FP048</span> to <span style="color: #FF0000">FP059</span> variables (factor)
|      **[B.46]** <span style="color: #FF0000">FP114</span> variable (factor)
|      **[B.47]-[B.50]** <span style="color: #FF0000">FP119</span> to <span style="color: #FF0000">FP122</span> variable (factor)
|      **[B.51]-[B.88]** <span style="color: #FF0000">FP124</span> to <span style="color: #FF0000">FP161</span> variables (factor)
|      **[B.89]-[B.118]** <span style="color: #FF0000">FP172</span> to <span style="color: #FF0000">FP201</span> variables (factor)
|      **[B.119]-[B.124]** <span style="color: #FF0000">FP203</span> to <span style="color: #FF0000">FP208</span> variables (factor)
|      **[B.125]** <span style="color: #FF0000">NumSulfer</span> variable (numeric)
|      **[B.126]** <span style="color: #FF0000">NumChlorine</span> variable (numeric)
|      **[B.127]** <span style="color: #FF0000">NumHalogen</span> variable (numeric)
|
| **[C]** Low variance observed for 4 variables with Unique.Count.Ratio<0.01.
|      **[C.1]** <span style="color: #FF0000">NumDblBonds</span> variable (numeric)
|      **[C.2]** <span style="color: #FF0000">NumNitrogen</span> variable (numeric)
|      **[C.3]** <span style="color: #FF0000">NumSulfer</span> variable (numeric)
|      **[C.4]** <span style="color: #FF0000">NumRings</span> variable (numeric)
|
| **[D]** High skewness observed for 3 variables with Skewness>3 or Skewness<(-3).
|      **[D.1]** <span style="color: #FF0000">NumSulfer</span> variable (numeric)
|      **[D.2]** <span style="color: #FF0000">NumChlorine</span> variable (numeric)
|      **[D.3]** <span style="color: #FF0000">HydrophilicFactor</span> variable (numeric)
|
```{r section_1.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- Solubility_Train

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Index=c(1:length(names(DQA))),
  Column.Name= names(DQA), 
  Column.Type=sapply(DQA, function(x) class(x)), 
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all predictors
##################################
DQA.Predictors <- DQA[,!names(DQA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DQA.Predictors.Numeric <- DQA.Predictors[,-(grep("FP", names(DQA.Predictors)))]

if (length(names(DQA.Predictors.Numeric))>0) {
    print(paste0("There are ",
               (length(names(DQA.Predictors.Numeric))),
               " numeric predictor variable(s)."))
} else {
  print("There are no numeric predictor variables.")
}

##################################
# Listing all factor predictors
##################################
DQA.Predictors.Factor <-as.data.frame(lapply(DQA.Predictors[(grep("FP", names(DQA.Predictors)))],factor))

if (length(names(DQA.Predictors.Factor))>0) {
    print(paste0("There are ",
               (length(names(DQA.Predictors.Factor))),
               " factor predictor variable(s)."))
} else {
  print("There are no factor predictor variables.")
}

##################################
# Formulating a data quality assessment summary for factor predictors
##################################
if (length(names(DQA.Predictors.Factor))>0) {
  
  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }
  
  (DQA.Predictors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Factor), 
  Column.Type=sapply(DQA.Predictors.Factor, function(x) class(x)), 
  Unique.Count=sapply(DQA.Predictors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )
  
} 

##################################
# Formulating a data quality assessment summary for numeric predictors
##################################
if (length(names(DQA.Predictors.Numeric))>0) {
  
  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }
  
  (DQA.Predictors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Numeric), 
  Column.Type=sapply(DQA.Predictors.Numeric, function(x) class(x)), 
  Unique.Count=sapply(DQA.Predictors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Predictors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Predictors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Predictors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Predictors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Predictors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Predictors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )  
  
}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance predictors
##################################
if (length(names(DQA.Predictors.Factor))==0) {
  print("No factor predictors noted.")
} else if (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric predictors due to low unique count ratio noted.")
}

##################################
# Checking for skewed predictors
##################################
if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric predictors noted.")
}

```
##  1.3 Data Preprocessing

###  1.3.1 Outlier
|
| Outlier data assessment:
|
| **[A]** Outliers noted for 20 variables  with the numeric data visualized through a boxplot including observations classified as suspected outliers using the IQR criterion. The IQR criterion means that all observations above the (75th percentile + 1.5 x IQR) or below the (25th percentile - 1.5 x IQR) are suspected outliers, where IQR is the difference between the third quartile (75th percentile) and first quartile (25th percentile). Outlier treatment for numerical stability remains optional depending on potential model requirements for the subsequent steps.
|      **[A.1]** <span style="color: #FF0000">MolWeight	</span> variable (8 outliers detected)
|      **[A.2]** <span style="color: #FF0000">NumAtoms</span> variable (44 outliers detected)
|      **[A.3]** <span style="color: #FF0000">NumNonHAtoms</span> variable (15 outliers detected)
|      **[A.4]** <span style="color: #FF0000">NumBonds</span> variable (51 outliers detected)
|      **[A.5]** <span style="color: #FF0000">NumNonHBonds</span> variable (18 outliers detected)
|      **[A.6]** <span style="color: #FF0000">NumMultBonds</span> variable (6 outliers detected)
|      **[A.7]** <span style="color: #FF0000">NumRotBonds</span> variable (23 outliers detected)
|      **[A.8]** <span style="color: #FF0000">NumDblBonds</span> variable (3 outliers detected)
|      **[A.9]** <span style="color: #FF0000">NumAromaticBonds</span> variable (35 outliers detected)
|      **[A.10]** <span style="color: #FF0000">NumHydrogen</span> variable (32 outliers detected)
|      **[A.11]** <span style="color: #FF0000">NumCarbon</span> variable (35 outliers detected)
|      **[A.12]** <span style="color: #FF0000">NumNitrogen</span> variable (91 outliers detected)
|      **[A.13]** <span style="color: #FF0000">NumOxygen</span> variable (36 outliers detected)
|      **[A.14]** <span style="color: #FF0000">NumSulfer</span> variable (121 outliers detected)
|      **[A.15]** <span style="color: #FF0000">NumChlorine</span> variable (201 outliers detected)
|      **[A.16]** <span style="color: #FF0000">NumHalogen</span> variable (99 outliers detected)
|      **[A.17]** <span style="color: #FF0000">NumRings</span> variable (4 outliers detected)
|      **[A.18]** <span style="color: #FF0000">HydrophilicFactor</span> variable (53 outliers detected)
|      **[A.19]** <span style="color: #FF0000">SurfaceArea1</span> variable (19 outliers detected)
|      **[A.20]** <span style="color: #FF0000">SurfaceArea2</span> variable (12 outliers detected)
|
```{r section_1.3.1, warning=FALSE, message=FALSE, fig.width=15, fig.height=3}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,-(grep("FP", names(DPA.Predictors)))]

##################################
# Identifying outliers for the numeric predictors
##################################
OutlierCountList <- c()

for (i in 1:ncol(DPA.Predictors.Numeric)) {
  Outliers <- boxplot.stats(DPA.Predictors.Numeric[,i])$out
  OutlierCount <- length(Outliers)
  OutlierCountList <- append(OutlierCountList,OutlierCount)
  OutlierIndices <- which(DPA.Predictors.Numeric[,i] %in% c(Outliers))
  boxplot(DPA.Predictors.Numeric[,i], 
          ylab = names(DPA.Predictors.Numeric)[i], 
          main = names(DPA.Predictors.Numeric)[i],
          horizontal=TRUE)
  mtext(paste0(OutlierCount, " Outlier(s) Detected"))
}

OutlierCountSummary <- as.data.frame(cbind(names(DPA.Predictors.Numeric),(OutlierCountList)))
names(OutlierCountSummary) <- c("NumericPredictors","OutlierCount")
OutlierCountSummary$OutlierCount <- as.numeric(as.character(OutlierCountSummary$OutlierCount))
NumericPredictorWithOutlierCount <- nrow(OutlierCountSummary[OutlierCountSummary$OutlierCount>0,])
print(paste0(NumericPredictorWithOutlierCount, " numeric variable(s) were noted with outlier(s)." ))

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA.Predictors.Numeric))

###################################
# Verifying the data dimensions
###################################
dim(DPA.Predictors.Numeric)

```
###  1.3.2 Zero and Near-Zero Variance
|
| Zero and near-zero variance data assessment:
|
| **[A]** Low variance noted for 127 variables from the previous data quality assessment using a lower threshold.
|
| **[B]** Low variance noted for 3 variables using a preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package. The <span style="color: #0000FF">nearZeroVar</span> method using both the <span style="color: #0000FF">freqCut</span> and <span style="color: #0000FF">uniqueCut</span> criteria set at 95/5 and 10, respectively, were applied on the dataset.
|      **[B.1]** <span style="color: #FF0000">FP154</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">FP199</span> variable (factor)
|      **[B.3]** <span style="color: #FF0000">FP200</span> variable (factor)
|
```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA))

##################################
# Identifying columns with low variance
###################################
DPA_LowVariance <- nearZeroVar(DPA,
                               freqCut = 95/5,
                               uniqueCut = 10,
                               saveMetrics= TRUE)
(DPA_LowVariance[DPA_LowVariance$nzv,])

if ((nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))==0){
  
  print("No low variance predictors noted.")
  
} else {

  print(paste0("Low variance observed for ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s) with First.Second.Mode.Ratio>4 and Unique.Count.Ratio<0.10."))
  
  DPA_LowVarianceForRemoval <- (nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))
  
  print(paste0("Low variance can be resolved by removing ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LowVarianceForRemoval) {
  DPA_LowVarianceRemovedVariable <- rownames(DPA_LowVariance[DPA_LowVariance$nzv,])[j]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LowVarianceRemovedVariable))
  }
  
  DPA %>%
  skim() %>%
  dplyr::filter(skim_variable %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,]))

  ##################################
  # Filtering out columns with low variance
  #################################
  DPA_ExcludedLowVariance <- DPA[,!names(DPA) %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,])]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLowVariance_Skimmed <- skim(DPA_ExcludedLowVariance))
}

###################################
# Verifying the data dimensions
###################################
dim(DPA_ExcludedLowVariance)

```
###  1.3.3 Collinearity
|
| High collinearity data assessment:
|
| **[A]** High correlation > 95% were noted for 2 variable pairs as confirmed using the preprocessing summaries from the <mark style="background-color: #CCECFF">**caret**</mark> and <mark style="background-color: #CCECFF">**lares**</mark> packages.
|      **[A.1]** <span style="color: #FF0000">NumNonHAtoms</span> and <span style="color: #FF0000">NumNonHBonds</span> variables (numeric)
|      **[A.2]** <span style="color: #FF0000">NumMultBonds</span> and <span style="color: #FF0000">NumAromaticBonds</span> variables (numeric)
|      **[A.3]** <span style="color: #FF0000">NumAtoms</span> and <span style="color: #FF0000">NumBonds</span> variables (numeric)
|
```{r section_1.3.3, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,-(grep("FP", names(DPA.Predictors)))]

##################################
# Visualizing pairwise correlation between predictors
##################################
DPA_CorrelationTest <- cor.mtest(DPA.Predictors.Numeric,
                       method = "pearson",
                       conf.level = .95)

corrplot(cor(DPA.Predictors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"), 
         method = "circle",
         type = "upper", 
         order = "original", 
         tl.col = "black", 
         tl.cex = 0.75,
         tl.srt = 90, 
         sig.level = 0.05, 
         p.mat = DPA_CorrelationTest$p,
         insig = "blank")



##################################
# Identifying the highly correlated variables
##################################
DPA_Correlation <-  cor(DPA.Predictors.Numeric, 
                        method = "pearson",
                        use="pairwise.complete.obs")
(DPA_HighlyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)]) > 0.95))

if (DPA_HighlyCorrelatedCount == 0) {
  print("No highly correlated predictors noted.")
} else {
  print(paste0("High correlation observed for ",
               (DPA_HighlyCorrelatedCount),
               " pairs of numeric variable(s) with Correlation.Coefficient>0.95."))
  
  (DPA_HighlyCorrelatedPairs <- corr_cross(DPA.Predictors.Numeric,
  max_pvalue = 0.05, 
  top = DPA_HighlyCorrelatedCount,
  rm.na = TRUE,
  grid = FALSE
))
  
}


if (DPA_HighlyCorrelatedCount > 0) {
  DPA_HighlyCorrelated <- findCorrelation(DPA_Correlation, cutoff = 0.95)
  
  (DPA_HighlyCorrelatedForRemoval <- length(DPA_HighlyCorrelated))
  
  print(paste0("High correlation can be resolved by removing ",
               (DPA_HighlyCorrelatedForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_HighlyCorrelatedForRemoval) {
  DPA_HighlyCorrelatedRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_HighlyCorrelated[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_HighlyCorrelatedRemovedVariable))
  }
  
  ##################################
  # Filtering out columns with high correlation
  #################################
  DPA_ExcludedHighCorrelation <- DPA[,-DPA_HighlyCorrelated]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedHighCorrelation_Skimmed <- skim(DPA_ExcludedHighCorrelation))

}

###################################
# Verifying the data dimensions
###################################
dim(DPA_ExcludedHighCorrelation)

```
###  1.3.4 Linear Dependencies
|
| Linear dependency data assessment:
|
| **[A]** Linear dependencies noted for 2 subsets of variables using the preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package applying the <span style="color: #0000FF">findLinearCombos</span> method which utilizes the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist). 
|
| **[B]** Subset 1
|      **[B.1]** <span style="color: #FF0000">NumNonHBonds</span> variable (numeric)
|      **[B.2]** <span style="color: #FF0000">NumAtoms</span> variable (numeric)
|      **[B.3]** <span style="color: #FF0000">NumNonHAtoms</span> variable (numeric)
|      **[B.3]** <span style="color: #FF0000">NumBonds</span> variable (numeric)
|
| **[C]** Subset 2
|      **[C.1]** <span style="color: #FF0000">NumHydrogen</span> variable (numeric)
|      **[C.2]** <span style="color: #FF0000">NumAtoms</span> variable (numeric)
|      **[C.3]** <span style="color: #FF0000">NumNonHAtoms</span> variable (numeric)
|
```{r section_1.3.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying the linearly dependent variables
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

(DPA_LinearlyDependentCount <- length(DPA_LinearlyDependent$linearCombos))

if (DPA_LinearlyDependentCount == 0) {
  print("No linearly dependent predictors noted.")
} else {
  print(paste0("Linear dependency observed for ",
               (DPA_LinearlyDependentCount),
               " subset(s) of numeric variable(s)."))
  
  for (i in 1:DPA_LinearlyDependentCount) {
    DPA_LinearlyDependentSubset <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$linearCombos[[i]]]
    print(paste0("Linear dependent variable(s) for subset ",
                 i,
                 " include: ",
                 DPA_LinearlyDependentSubset))
  }
  
}

##################################
# Identifying the linearly dependent variables for removal
##################################

if (DPA_LinearlyDependentCount > 0) {
  DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)
  
  DPA_LinearlyDependentForRemoval <- length(DPA_LinearlyDependent$remove)
  
  print(paste0("Linear dependency can be resolved by removing ",
               (DPA_LinearlyDependentForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LinearlyDependentForRemoval) {
  DPA_LinearlyDependentRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$remove[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LinearlyDependentRemovedVariable))
  }
  
  ##################################
  # Filtering out columns with linear dependency
  #################################
  DPA_ExcludedLinearlyDependent <- DPA[,-DPA_LinearlyDependent$remove]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLinearlyDependent_Skimmed <- skim(DPA_ExcludedLinearlyDependent))

}

###################################
# Verifying the data dimensions
###################################
dim(DPA_ExcludedLinearlyDependent)

```

###  1.3.5 Shape Transformation
|
| Data transformation assessment:
|
| **[A]** A number of numeric variables in the dataset were observed to be right-skewed which required shape transformation for data distribution stability. Considering that all numeric variables were strictly positive values, the <span style="color: #0000FF">BoxCox</span> method from the <mark style="background-color: #CCECFF">**caret**</mark> package was used to transform their distributional shapes.
|
```{r section_1.3.5, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,-(grep("FP", names(DPA.Predictors)))]

##################################
# Applying a Box-Cox transformation
##################################
DPA_BoxCox <- preProcess(DPA.Predictors.Numeric, method = c("BoxCox"))
DPA_BoxCoxTransformed <- predict(DPA_BoxCox, DPA.Predictors.Numeric)

##################################
# Gathering descriptive statistics
##################################
(DPA_BoxCoxTransformedSkimmed <- skim(DPA_BoxCoxTransformed))

###################################
# Verifying the data dimensions
###################################
dim(DPA_BoxCoxTransformed)

```

###  1.3.6 Centering and Scaling
|
| Centering and scaling data assessment:
|
| **[A]** To maintain numerical stability during modelling, centering and scaling transformations were applied on the transformed numeric variables. The <span style="color: #0000FF">center</span> method from the <mark style="background-color: #CCECFF">**caret**</mark> package was implemented which subtracts the average value of a numeric variable to all the values. As a result of centering, the variables had zero mean values. In addition, the <span style="color: #0000FF">scale</span> method, also from the <mark style="background-color: #CCECFF">**caret**</mark> package, was applied which performs a center transformation with each value of the variable divided by its standard deviation. Scaling the data coerced the values to have a common standard deviation of one.
|
```{r section_1.3.6, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Solubility_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,-(grep("FP", names(DPA.Predictors)))]

##################################
# Applying a Box-Cox transformation
##################################
DPA_BoxCox <- preProcess(DPA.Predictors.Numeric, method = c("BoxCox"))
DPA_BoxCoxTransformed <- predict(DPA_BoxCox, DPA.Predictors.Numeric)

##################################
# Applying a center and scale data transformation
##################################
DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaled <- preProcess(DPA_BoxCoxTransformed, method = c("center","scale"))
DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed <- predict(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaled, DPA_BoxCoxTransformed)

##################################
# Gathering descriptive statistics
##################################
(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformedSkimmed <- skim(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed))

###################################
# Verifying the data dimensions
###################################
dim(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed)

```

###  1.3.7 Pre-Processed Dataset
|
| Preliminary dataset assessment:
|
| **[A]** 1267 rows (observations)
|      **[A.1]** Train Set = 951 observations
|      **[A.2]** Test Set = 316 observations
| 
| **[B]** 221 columns (variables)
|      **[B.1]** 1/221 response = <span style="color: #FF0000">Log_Solubility_Class</span> variable (factor)
|             **[B.1.1]** Levels = <span style="color: #FF0000">Log_Solubility_Class=Low</span> < <span style="color: #FF0000">Log_Solubility_Class=High</span>
|      **[B.2]** 220/221 predictors = All remaining variables (205/220 factor + 15/220 numeric)
| 
| **[C]** Pre-processing actions applied:
|      **[C.1]** Centering, scaling and shape transformation applied to improve data quality
|      **[C.2]** No outlier treatment applied since the high values noted were contextually valid and sensible 
|      **[C.3]** 3 predictors removed due to zero or near-zero variance 
|      **[C.4]** 3 predictors removed due to high correlation
|      **[C.5]** 2 predictors removed due to linear dependencies
|
```{r section_1.3.7, warning=FALSE, message=FALSE}
##################################
# Creating the pre-modelling
# train set
##################################
Log_Solubility_Class <- DPA$Log_Solubility_Class 
PMA.Predictors.Factor   <- DPA.Predictors[,(grep("FP", names(DPA.Predictors)))]
PMA.Predictors.Factor   <- as.data.frame(lapply(PMA.Predictors.Factor,factor))
PMA.Predictors.Numeric  <- DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed
PMA_BoxCoxTransformed_CenteredScaledTransformed <- cbind(Log_Solubility_Class,PMA.Predictors.Factor,PMA.Predictors.Numeric)

##################################
# Filtering out columns noted with data quality issues including
# zero and near-zero variance,
# high correlation and linear dependencies
# to create the pre-modelling dataset
##################################
PMA_BoxCoxTransformed_CenteredScaledTransformed_ExcludedLowVariance_ExcludedLinearlyDependent_ExcludedHighCorrelation <- PMA_BoxCoxTransformed_CenteredScaledTransformed[,!names(PMA_BoxCoxTransformed_CenteredScaledTransformed) %in% c("FP154","FP199","FP200","NumNonHBonds","NumHydrogen","NumNonHAtoms","NumAromaticBonds","NumAtoms")]

PMA_PreModelling_Train <- PMA_BoxCoxTransformed_CenteredScaledTransformed_ExcludedLowVariance_ExcludedLinearlyDependent_ExcludedHighCorrelation

##################################
# Gathering descriptive statistics
##################################
(PMA_PreModelling_Train_Skimmed <- skim(PMA_PreModelling_Train))

###################################
# Verifying the data dimensions
# for the train set
###################################
dim(PMA_PreModelling_Train)

##################################
# Formulating the test set
##################################
DPA_Test <- Solubility_Test
DPA_Test.Predictors <- DPA_Test[,!names(DPA_Test) %in% c("Log_Solubility_Class")]
DPA_Test.Predictors.Numeric <- DPA_Test.Predictors[,-(grep("FP", names(DPA_Test.Predictors)))]
DPA_Test_BoxCox <- preProcess(DPA_Test.Predictors.Numeric, method = c("BoxCox"))
DPA_Test_BoxCoxTransformed <- predict(DPA_Test_BoxCox, DPA_Test.Predictors.Numeric)
DPA_Test.Predictors.Numeric_BoxCoxTransformed_CenteredScaled <- preProcess(DPA_Test_BoxCoxTransformed, method = c("center","scale"))
DPA_Test.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed <- predict(DPA_Test.Predictors.Numeric_BoxCoxTransformed_CenteredScaled, DPA_Test_BoxCoxTransformed)

##################################
# Creating the pre-modelling
# test set
##################################
Log_Solubility_Class <- DPA_Test$Log_Solubility_Class 
PMA_Test.Predictors.Factor   <- DPA_Test.Predictors[,(grep("FP", names(DPA_Test.Predictors)))]
PMA_Test.Predictors.Factor   <- as.data.frame(lapply(PMA_Test.Predictors.Factor,factor))
PMA_Test.Predictors.Numeric  <- DPA_Test.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed
PMA_Test_BoxCoxTransformed_CenteredScaledTransformed <- cbind(Log_Solubility_Class,PMA_Test.Predictors.Factor,PMA_Test.Predictors.Numeric)
PMA_Test_BoxCoxTransformed_CenteredScaledTransformed_ExcludedLowVariance_ExcludedLinearlyDependent_ExcludedHighCorrelation <- PMA_Test_BoxCoxTransformed_CenteredScaledTransformed[,!names(PMA_Test_BoxCoxTransformed_CenteredScaledTransformed) %in% c("FP154","FP199","FP200","NumNonHBonds","NumHydrogen","NumNonHAtoms","NumAromaticBonds","NumAtoms")]

PMA_PreModelling_Test <- PMA_Test_BoxCoxTransformed_CenteredScaledTransformed_ExcludedLowVariance_ExcludedLinearlyDependent_ExcludedHighCorrelation

##################################
# Gathering descriptive statistics
##################################
(PMA_PreModelling_Test_Skimmed <- skim(PMA_PreModelling_Test))

###################################
# Verifying the data dimensions
# for the test set
###################################
dim(PMA_PreModelling_Test)

```
## 1.4 Data Exploration
|
| Exploratory data analysis:
|
| **[A]** Numeric variables which demonstrated differential relationships with the <span style="color: #FF0000">Log_Solubility_Class</span> response variable include:
|      **[A.1]** <span style="color: #FF0000">MolWeight</span> variable (numeric)
|      **[A.2]** <span style="color: #FF0000">NumCarbon</span> variable (numeric)
|      **[A.3]** <span style="color: #FF0000">NumChlorine</span> variable (numeric)
|      **[A.4]** <span style="color: #FF0000">NumHalogen</span> variable (numeric)
|      **[A.5]** <span style="color: #FF0000">NumMultBonds</span> variable (numeric)
|
| **[B]** Factor variables which demonstrated relatively better differentiation of the <span style="color: #FF0000">Log_Solubility_Class</span> response variable between its <span style="color: #FF0000">1</span> and <span style="color: #FF0000">0</span> structure levels include:
|      **[B.1]** <span style="color: #FF0000">FP207</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">FP190</span> variable (factor)
|      **[B.3]** <span style="color: #FF0000">FP197</span> variable (factor)
|      **[B.4]** <span style="color: #FF0000">FP196</span> variable (factor)
|      **[B.5]** <span style="color: #FF0000">FP193</span> variable (factor)
|      **[B.6]** <span style="color: #FF0000">FP184</span> variable (factor)
|      **[B.7]** <span style="color: #FF0000">FP172</span> variable (factor)
|      **[B.8]** <span style="color: #FF0000">FP149</span> variable (factor)
|      **[B.9]** <span style="color: #FF0000">FP112</span> variable (factor)
|      **[B.10]** <span style="color: #FF0000">FP107</span> variable (factor)
|      **[B.11]** <span style="color: #FF0000">FP089</span> variable (factor)
|      **[B.12]** <span style="color: #FF0000">FP079</span> variable (factor)
|      **[B.13]** <span style="color: #FF0000">FP076</span> variable (factor)
|      **[B.14]** <span style="color: #FF0000">FP072</span> variable (factor)
|      **[B.15]** <span style="color: #FF0000">FP071</span> variable (factor)
|      **[B.16]** <span style="color: #FF0000">FP070</span> variable (factor)
|      **[B.17]** <span style="color: #FF0000">FP065</span> variable (factor)
|      **[B.18]** <span style="color: #FF0000">FP059</span> variable (factor)
|      **[B.19]** <span style="color: #FF0000">FP054</span> variable (factor)
|      **[B.20]** <span style="color: #FF0000">FP056</span> variable (factor)
|      **[B.21]** <span style="color: #FF0000">FP053</span> variable (factor)
|      **[B.22]** <span style="color: #FF0000">FP049</span> variable (factor)
|      **[B.23]** <span style="color: #FF0000">FP044</span> variable (factor)
|      **[B.24]** <span style="color: #FF0000">FP041</span> variable (factor)
|      **[B.25]** <span style="color: #FF0000">FP039</span> variable (factor)
|      **[B.26]** <span style="color: #FF0000">FP014</span> variable (factor)
|      **[B.27]** <span style="color: #FF0000">FP013</span> variable (factor)
|
```{r section_1.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
EDA <- PMA_PreModelling_Train

##################################
# Listing all predictors
##################################
EDA.Predictors <- EDA[,!names(EDA) %in% c("Log_Solubility_Class")]

##################################
# Listing all numeric predictors
##################################
EDA.Predictors.Numeric <- EDA.Predictors[,sapply(EDA.Predictors, is.numeric)]
ncol(EDA.Predictors.Numeric)
names(EDA.Predictors.Numeric)

##################################
# Listing all factor predictors
##################################
EDA.Predictors.Factor <- EDA.Predictors[,sapply(EDA.Predictors, is.factor)]
ncol(EDA.Predictors.Factor)
names(EDA.Predictors.Factor)

##################################
# Formulating the box plots
##################################
featurePlot(x = EDA.Predictors.Numeric, 
            y = EDA$Log_Solubility_Class,
            plot = "box",
            scales = list(x = list(relation="free", rot = 90), 
                          y = list(relation="free")),
            adjust = 1.5, 
            pch = "|")

##################################
# Restructuring the dataset for
# for barchart analysis
##################################
Log_Solubility_Class <- DPA$Log_Solubility_Class
EDA.Bar.Source <- as.data.frame(cbind(Log_Solubility_Class,
                     EDA.Predictors.Factor))
ncol(EDA.Bar.Source)


##################################
# Creating a function to formulate
# the proportions table
##################################
EDA.PropTable.Function <- function(FactorVar) {
  EDA.Bar.Source.FactorVar <- EDA.Bar.Source[,c("Log_Solubility_Class",
                                          FactorVar)]
  EDA.Bar.Source.FactorVar.Prop <- as.data.frame(prop.table(table(EDA.Bar.Source.FactorVar), 2))
  names(EDA.Bar.Source.FactorVar.Prop)[2] <- "Structure"
  EDA.Bar.Source.FactorVar.Prop$Variable <- rep(FactorVar,nrow(EDA.Bar.Source.FactorVar.Prop))
  
  return(EDA.Bar.Source.FactorVar.Prop)

}

EDA.Bar.Source.FactorVar.Prop.Group5 <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[162]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[163]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[164]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[165]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[166]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[167]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[168]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[169]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[170]),                           
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[171]),                           
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[172]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[173]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[174]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[175]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[176]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[177]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[178]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[179]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[180]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[181]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[182]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[183]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[184]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[185]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[186]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[187]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[188]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[189]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[190]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[191]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[192]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[193]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[194]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[195]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[196]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[197]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[198]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[199]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[200]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[201]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[202]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[203]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[204]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[205]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[206]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group5[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group5[,2] | EDA.Bar.Source.FactorVar.Prop.Group5[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group5,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group5[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(9,5))))


EDA.Bar.Source.FactorVar.Prop.Group4 <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[122]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[123]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[124]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[125]),                          
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[126]),                           
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[127]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[128]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[129]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[130]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[131]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[132]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[133]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[134]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[135]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[136]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[137]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[138]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[139]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[140]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[141]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[142]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[143]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[144]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[145]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[146]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[147]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[148]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[149]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[150]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[151]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[152]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[153]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[154]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[155]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[156]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[157]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[158]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[159]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[160]),                          
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[161]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group4[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group4[,2] | EDA.Bar.Source.FactorVar.Prop.Group4[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group4,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group4[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(9,5))))


EDA.Bar.Source.FactorVar.Prop.Group3 <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[82]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[83]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[84]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[85]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[86]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[87]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[88]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[89]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[90]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[91]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[92]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[93]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[94]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[95]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[96]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[97]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[98]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[99]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[100]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[101]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[102]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[103]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[104]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[105]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[106]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[107]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[108]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[109]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[110]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[111]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[112]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[113]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[114]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[115]),                           
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[116]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[117]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[118]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[119]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[120]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[121]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group3[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group3[,2] | EDA.Bar.Source.FactorVar.Prop.Group3[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group3,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group3[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(9,5))))


EDA.Bar.Source.FactorVar.Prop.Group2 <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[42]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[43]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[44]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[45]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[46]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[47]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[48]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[49]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[50]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[51]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[52]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[53]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[54]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[55]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[56]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[57]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[58]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[59]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[60]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[61]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[62]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[63]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[64]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[65]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[66]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[67]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[68]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[69]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[70]),                            
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[71]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[72]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[73]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[74]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[75]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[76]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[77]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[78]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[79]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[80]),                            
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[81]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group2[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group2[,2] | EDA.Bar.Source.FactorVar.Prop.Group2[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group2,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group2[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(9,5))))


EDA.Bar.Source.FactorVar.Prop.Group1 <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[2]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[3]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[4]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[5]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[6]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[7]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[8]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[9]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[10]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[11]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[12]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[13]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[14]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[15]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[16]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[17]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[18]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[19]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[20]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[21]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[22]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[23]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[24]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[25]),                            
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[26]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[27]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[28]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[29]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[30]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[31]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[32]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[33]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[34]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[35]),                            
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[36]),                            
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[37]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[38]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[39]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[40]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[41]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group1[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group1[,2] | EDA.Bar.Source.FactorVar.Prop.Group1[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group1,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group1[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(9,5))))


```

## 1.5 Model-Independent Feature Importance Metrics

###  1.5.1 Receiver Operating Characteristic Curve - Area Under Curve (ROC_AUC)
|
| [Receiver Operating Characteristic Curve - Area Under Curve](https://www.semanticscholar.org/paper/Signal-detection-theory-and-ROC-analysis-Egan/a2cf3479c3b5c96b8ee8c353876fba5048a39fb7) involves a  plot that demonstrates the performance of a classification prediction model to discriminate between two levels of a categorical response when compared to a gold standard, using the true positive rate (or Sensitivity) and the false positive rate (or 1-Specificity) for a range of threshold settings. The area under the ROC curve measures its discrimination power which is the ability of the model to distinguish between two classes or groups. The presence of high ROC Curve AUC indicates the univariate discrimination of the categorical response by the numeric predictors.
|
| **[A]** The receiver operating characteristic curve - area under curve metric  was obtained using the <mark style="background-color: #CCECFF">**caret**</mark> package. High raw values of the metric indicate that the numeric predictors were associated with the factor response.
|
| **[B]** The numeric predictors which demonstrated the best feature importance in terms of this metric are as follows:
|      **[B.1]** <span style="color: #FF0000">MolWeight</span> = 0.84419
|      **[B.2]** <span style="color: #FF0000">NumCarbon</span> = 0.84088
|      **[B.3]** <span style="color: #FF0000">NumBonds</span> = 0.78932
|      **[B.4]** <span style="color: #FF0000">NumRings</span> = 0.74385
|      **[B.5]** <span style="color: #FF0000">NumMultBonds</span> = 0.72301
|
```{r section_1.5.1, warning=FALSE, message=FALSE}
##################################
# Filtering in the numeric predictors
# with the factor response variable
##################################
PMA_PreModelling_Train_Numeric <- PMA_PreModelling_Train[,!grepl("FP", names(PMA_PreModelling_Train))]
dim(PMA_PreModelling_Train_Numeric)
str(PMA_PreModelling_Train_Numeric)
summary(PMA_PreModelling_Train_Numeric)

##################################
# Obtaining the ROC AUC
##################################
ROC_AUC <- filterVarImp(x = PMA_PreModelling_Train_Numeric[, 2:ncol(PMA_PreModelling_Train_Numeric)],
                        y = PMA_PreModelling_Train_Numeric$Log_Solubility_Class)

##################################
# Formulating the summary table
##################################
ROC_AUC_Summary <- ROC_AUC 

ROC_AUC_Summary$Predictor <- rownames(ROC_AUC)
names(ROC_AUC_Summary)[1] <- "ROC_AUC"
ROC_AUC_Summary$Metric <- rep("ROC_AUC",nrow(ROC_AUC))

ROC_AUC_Summary

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ ROC_AUC | Metric, 
        ROC_AUC_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

```

###  1.5.2 Absolute T-Test Statistic (ATS)
|
| [T-Test Statistic](https://www.jstor.org/stable/2685564?seq=1#page_scan_tab_contents), as derived from implementing a T-Test, measures the magnitude of the difference between the two group means being compared and is used to estimate the likelihood that this difference exists purely by chance. The test of hypothesis involved applying T-Test to evaluate for any significant differences in the means of the numeric predictors between the two classes of the categorical response. The presence of high T-Test statistic indicates the univariate discrimination of the categorical response by the numeric predictors.
|
| **[A]** The absolute T-test statistic was obtained using the <mark style="background-color: #CCECFF">**stats**</mark> package. High absolute values of the metric indicate that the numeric predictors were associated with the factor response.
|
| **[B]** The numeric predictors which demonstrated the best feature importance in terms of this metric are as follows:
|      **[B.1]** <span style="color: #FF0000">MolWeight</span> = 22.06757
|      **[B.2]** <span style="color: #FF0000">NumCarbon</span> = 21.00363
|      **[B.3]** <span style="color: #FF0000">NumBonds</span> = 16.49077
|      **[B.4]** <span style="color: #FF0000">NumRings</span> = 14.39568
|      **[B.5]** <span style="color: #FF0000">NumMultBonds</span> = 13.09205
|
```{r section_1.5.2, warning=FALSE, message=FALSE}
##################################
# Obtaining the t-test statistics
##################################
ATS <- apply(PMA_PreModelling_Train_Numeric[, 2:ncol(PMA_PreModelling_Train_Numeric)],
             2,
             function(x, y){
               tStats <- t.test(x ~ y)[c("statistic", "p.value", "estimate")]
               unlist(tStats)},
             y=PMA_PreModelling_Train_Numeric$Log_Solubility_Class)

##################################
# Formulating the summary table
##################################
ATS_Summary <- as.data.frame(t(ATS))
names(ATS_Summary) <- c("t.Statistic", "t.Test_P.Value", "Mean0", "Mean1")
ATS_Summary$Predictor <- names(PMA_PreModelling_Train_Numeric[,-1])
ATS_Summary$Metric <- rep("ATS", nrow(ATS_Summary))
ATS_Summary$ATS <- abs(ATS_Summary$t.Statistic)

ATS_Summary

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ ATS | Metric, 
        ATS_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })
```

###  1.5.3 Maximal Information Coefficient (MIC)
|
| [Maximal Information Coefficient](https://www.science.org/doi/10.1126/science.1205438) is an information theory-based measure of two-variable dependence through the computation of the mutual information normalized by the minimum joint entropy. It evaluates the strength of linear or non-linear association using binning as a means to apply mutual information between continuous random variables and selecting the maximum over many possible grids. The presence of high coefficient values indicate the univariate association between the numeric predictors and the numeric response.
|
| **[A]** The maximal information coefficient was obtained using the <mark style="background-color: #CCECFF">**minerva**</mark> package. High raw values of the metric indicate that the numeric predictors were associated with the factor response.
|
| **[B]** The numeric predictors which demonstrated the best feature importance in terms of this metric are as follows:
|      **[B.1]** <span style="color: #FF0000">MolWeight</span> = 0.46368
|      **[B.2]** <span style="color: #FF0000">HydrophilicFactor</span> = 0.32734
|      **[B.3]** <span style="color: #FF0000">NumCarbon</span> = 0.31544
|      **[B.4]** <span style="color: #FF0000">NumBonds</span> = 0.28498
|      **[B.5]** <span style="color: #FF0000">SurfaceArea2</span> = 0.31618
|
```{r section_1.5.3, warning=FALSE, message=FALSE}
##################################
# Obtaining the maximal information coefficient
##################################
MIC <- mine(x = PMA_PreModelling_Train_Numeric[, 2:ncol(PMA_PreModelling_Train_Numeric)],
            y = ifelse(PMA_PreModelling_Train_Numeric$Log_Solubility_Class=="High",1,0))$MIC

##################################
# Formulating the summary table
##################################
MIC_Summary <- data.frame(Predictor = names(PMA_PreModelling_Train_Numeric)[2:ncol(PMA_PreModelling_Train_Numeric)],
                          MIC = MIC[,1],
                          Metric = rep("MIC", length(MIC)))

MIC_Summary

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ MIC | Metric, 
        MIC_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })
```

###  1.5.4 Relief Values (RV)
|
| [Relief Values](https://link.springer.com/article/10.1023/A:1025667309714) are heuristic measures which estimate the quality of variables according to how well their values compare to instances that are near to each other, but are efficient in detecting contextual information even with strong dependencies between attributes. Random instances and the corresponding K-nearest instances are selected, with the the weights for the different prediction values, different attributes and different prediction consolidated. The rank of the instance in a sequence of instances ordered by the distance is taken into account based on a a user-defined parameter controlling the influence of the distance. The contributions of each K-nearest instances are normalized by dividing the results with the sum of all K contributions. The presence of high relief values indicate the univariate association between the numeric predictors and the numeric response.
|
| **[A]** The relief values statistic was obtained using the <mark style="background-color: #CCECFF">**CORElearn**</mark> package. High raw values of the metric indicate that the numeric predictors were associated with the factor response.
|
| **[B]** The numeric predictors which demonstrated the best feature importance in terms of this metric are as follows:
|      **[B.1]** <span style="color: #FF0000">MolWeight</span> = 0.30039
|      **[B.2]** <span style="color: #FF0000">NumCarbon</span> = 0.28938
|      **[B.3]** <span style="color: #FF0000">NumRings</span> = 0.20600
|      **[B.4]** <span style="color: #FF0000">NumBonds</span> = 0.20575
|      **[B.5]** <span style="color: #FF0000">NumNitrogen</span> = 0.10800
|
```{r section_1.5.4, warning=FALSE, message=FALSE}
summary(PMA_PreModelling_Train_Numeric)
##################################
# Obtaining the relief values
##################################
set.seed(12345678)
RV <- attrEval(Log_Solubility_Class ~ .,
               data = PMA_PreModelling_Train_Numeric,
               estimator = "ReliefFequalK",
               ReliefIterations = 50)

##################################
# Formulating the summary table
##################################
RV_Summary <- data.frame(Predictor = names(RV),
                         RV = RV,
                         Metric = rep("RV", length(RV)))

RV_Summary

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ RV | Metric,
        RV_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })
```

###  1.5.5 Volcano Plot - Fisher's Exact Test (VP_F)
|
| **[A]** The volcano plot - Fisher's Exact Test p-value was obtained using the <mark style="background-color: #CCECFF">**stats**</mark> package. High raw values of the negative logarithm of the metric, and the absolute log odds ratio indicate that the factor predictors were associated with the factor response.
|
| **[B]** The factor predictors which demonstrated the best feature importance in terms of the negative logarithm of the Fisher's Exact Test p-value are as follows:
|      **[B.1]** <span style="color: #FF0000">FP076</span> = 44.20850
|      **[B.2]** <span style="color: #FF0000">FP089</span> = 31.66852
|      **[B.3]** <span style="color: #FF0000">FP112</span> = 27.56836
|      **[B.4]** <span style="color: #FF0000">FP172</span> = 23.86142
|      **[B.5]** <span style="color: #FF0000">FP065</span> = 23.62888
|
| **[C]** The factor predictors which demonstrated the best feature importance in terms of the absolute log odds ratio are as follows:
|      **[C.1]** <span style="color: #FF0000">FP044</span> = 2.911268
|      **[C.2]** <span style="color: #FF0000">FP193</span> = 2.50206
|      **[C.3]** <span style="color: #FF0000">FP172</span> = 2.09503
|      **[C.4]** <span style="color: #FF0000">FP076</span> = 2.08379
|      **[C.5]** <span style="color: #FF0000">FP184</span> = 1.98819
|
```{r section_1.5.6, warning=FALSE, message=FALSE}
##################################
# Filtering in the factor predictors
# with the numeric response variable
##################################
PMA_PreModelling_Train_Factor <- PMA_PreModelling_Train[,grepl("FP", names(PMA_PreModelling_Train))]
PMA_PreModelling_Train_Factor$Log_Solubility_Class <- PMA_PreModelling_Train$Log_Solubility
dim(PMA_PreModelling_Train_Factor)
str(PMA_PreModelling_Train_Factor)
summary(PMA_PreModelling_Train_Factor)

##################################
# Obtaining the Fisher exact test statistics
##################################
VP_F <- function(x, y){
  tab <- table(x, y)
  fet <- fisher.test(tab)
  out <- c(FET_OR = fet$estimate,
           FET_P.Value = fet$p.value)}

##################################
# Formulating the summary table
##################################
VP_F_Summary <- lapply(PMA_PreModelling_Train_Factor, 
                       VP_F, 
                       y = PMA_PreModelling_Train_Factor$Log_Solubility_Class)
VP_F_Summary <- as.data.frame(do.call("rbind", VP_F_Summary))
VP_F_Summary$Predictor <- names(PMA_PreModelling_Train_Factor)
VP_F_Summary <- VP_F_Summary[-nrow(VP_F_Summary),]
VP_F_Summary$Metric <- rep("VP_F", nrow(VP_F_Summary))
VP_F_Summary$NegativeLog10_FET_P.Value <- -log10(VP_F_Summary$FET_P.Value)
VP_F_Summary$LogOddsRatio <- log(VP_F_Summary[,1])
VP_F_Summary$AbsoluteLogOddsRatio <- abs(VP_F_Summary$LogOddsRatio)

VP_F_Summary$Group <- ifelse(rownames(VP_F_Summary)=="FP076","FP076",
                             ifelse(rownames(VP_F_Summary)=="FP089","FP089",
                                    ifelse(rownames(VP_F_Summary)=="FP112","FP112",
                                           ifelse(rownames(VP_F_Summary)=="FP044","FP044",
                                                  ifelse(rownames(VP_F_Summary)=="FP193","FP193",
                                                         "Others")))))

VP_F_Summary

##################################
# Selecting the best-performing
# predictors based from metrics
##################################
VP_F_Summary_Top15_FETPValue <- VP_F_Summary[order(VP_F_Summary$NegativeLog10_FET_P.Value,decreasing=TRUE),]
(VP_F_Summary_Top15_FETPValue <- VP_F_Summary_Top15_FETPValue[1:15,])

VP_F_Summary_Top15_AbsoluteLogOddsRatio <- VP_F_Summary[order(VP_F_Summary$AbsoluteLogOddsRatio,decreasing=TRUE),]
(VP_F_Summary_Top15_AbsoluteLogOddsRatio <- VP_F_Summary_Top15_AbsoluteLogOddsRatio[1:15,])

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ NegativeLog10_FET_P.Value | Metric, 
        VP_F_Summary_Top15_FETPValue,
        origin = 0,
        xlab = "-Log10(Fisher Exact Test P-Value)",
        type = c("p","h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

dotplot(Predictor ~ AbsoluteLogOddsRatio | Metric, 
        VP_F_Summary_Top15_AbsoluteLogOddsRatio,
        origin = 0,
        xlab = "ABsolute Log Odds Ratio",
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

```

###  1.5.6 Volcano Plot - Gain Ratio (VP_G)
|
| **[A]** The volcano plot - gain ratio was obtained using the <mark style="background-color: #CCECFF">**COREtrain**</mark> package. High raw values of the metric, and the absolute log odds ratio indicate that the factor predictors were associated with the factor response.
|
| **[B]** The factor predictors which demonstrated the best feature importance in terms of the gain ratio are as follows:
|      **[B.1]** <span style="color: #FF0000">FP076</span> = 0.16518
|      **[B.2]** <span style="color: #FF0000">FP044</span> = 0.14858
|      **[B.3]** <span style="color: #FF0000">FP089</span> = 0.13291
|      **[B.4]** <span style="color: #FF0000">FP172</span> = 0.13177
|      **[B.5]** <span style="color: #FF0000">FP112</span> = 0.13074
|
| **[C]** The factor predictors which demonstrated the best feature importance in terms of the absolute log odds ratio are as follows:
|      **[C.1]** <span style="color: #FF0000">FP044</span> = 2.911268
|      **[C.2]** <span style="color: #FF0000">FP193</span> = 2.50206
|      **[C.3]** <span style="color: #FF0000">FP172</span> = 2.09503
|      **[C.4]** <span style="color: #FF0000">FP076</span> = 2.08379
|      **[C.5]** <span style="color: #FF0000">FP184</span> = 1.98819
|
```{r section_1.5.7, warning=FALSE, message=FALSE}
##################################
# Obtaining the gain ratio
##################################
VP_G <- function(x, y){
  tab <- table(x, y)
  fet <- fisher.test(tab)
  out <- c(FET_OR = fet$estimate,
           Gain = attrEval(y ~ x, estimator="GainRatio"))}

##################################
# Formulating the summary table
##################################
VP_G_Summary <- lapply(PMA_PreModelling_Train_Factor, 
                       VP_G, 
                       y = PMA_PreModelling_Train_Factor$Log_Solubility_Class)
VP_G_Summary <- as.data.frame(do.call("rbind", VP_G_Summary))
VP_G_Summary$Gain <- VP_G_Summary$Gain.x
VP_G_Summary$Gain.x <- NULL
VP_G_Summary$Predictor <- names(PMA_PreModelling_Train_Factor)
VP_G_Summary <- VP_G_Summary[-nrow(VP_G_Summary),]
VP_G_Summary$Metric <- rep("VP_G", nrow(VP_G_Summary))
VP_G_Summary$LogOddsRatio <- log(VP_G_Summary[,1])
VP_G_Summary$AbsoluteLogOddsRatio <- abs(VP_G_Summary$LogOddsRatio)

VP_G_Summary$Group <- ifelse(rownames(VP_G_Summary)=="FP076","FP076",
                             ifelse(rownames(VP_G_Summary)=="FP089","FP089",
                                    ifelse(rownames(VP_G_Summary)=="FP172","FP172",
                                           ifelse(rownames(VP_G_Summary)=="FP044","FP044",
                                                  ifelse(rownames(VP_G_Summary)=="FP193","FP193",
                                                         "Others")))))

VP_G_Summary

##################################
# Selecting the best-performing
# predictors based from metrics
##################################
VP_G_Summary_Top15_Gain <- VP_G_Summary[order(VP_G_Summary$Gain,decreasing=TRUE),]
(VP_G_Summary_Top15_Gain <- VP_G_Summary_Top15_Gain[1:15,])

VP_G_Summary_Top15_AbsoluteLogOddsRatio <- VP_G_Summary[order(VP_G_Summary$AbsoluteLogOddsRatio,decreasing=TRUE),]
(VP_G_Summary_Top15_AbsoluteLogOddsRatio <- VP_G_Summary_Top15_AbsoluteLogOddsRatio[1:15,])

##################################
# Exploring predictor performance
##################################
dotplot(Predictor ~ Gain | Metric, 
        VP_G_Summary_Top15_Gain,
        origin = 0,
        xlab = "Gain Ratio",
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

dotplot(Predictor ~ AbsoluteLogOddsRatio | Metric, 
        VP_G_Summary_Top15_AbsoluteLogOddsRatio,
        origin = 0,
        xlab = "Absolute Log Odds Ratio",
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

```

## 1.6 Evaluation Summary
|
| **[A]** The model-independent feature importance for all numeric predictors were evaluated in terms of the following metrics:
|      **[A.1]** ROC_AUC: Receiver Operating Characteristic Curve - Area Under Curve (<mark style="background-color: #CCECFF">**caret**</mark> package)
|      **[A.2]** ATS : Absolute T-Test Statistic (<mark style="background-color: #CCECFF">**stats**</mark> package)
|      **[A.3]** MIC: Maximal Information Coefficient (<mark style="background-color: #CCECFF">**minerva**</mark> package) 
|      **[A.4]** RV: Relief Values (<mark style="background-color: #CCECFF">**CORElearn**</mark> package) 
|
| **[B]** The numeric predictors which demonstrated the most consistent feature importance across the given metrics are as follows:
|      **[B.1]** <span style="color: #FF0000">MolWeight</span>
|      **[B.2]** <span style="color: #FF0000">NumCarbon</span>
|      **[B.3]** <span style="color: #FF0000">NumMultBonds</span>
|      **[B.4]** <span style="color: #FF0000">NumBonds</span>
|      **[B.5]** <span style="color: #FF0000">NumRings</span>
|
| **[C]** The model-independent feature importance for all factor predictors were evaluated in terms of the following metrics:
|      **[C.1]** VP_F: Volcano Plot - Fisher’s Exact Test (<mark style="background-color: #CCECFF">**stats**</mark> package)
|      **[C.2]** VP_G: Volcano Plot - Gain Ratio (<mark style="background-color: #CCECFF">**CORElearn**</mark> package)
|
| **[D]** The factor predictors which demonstrated the most consistent feature importance across the given metrics are as follows:
|      **[D.1]** <span style="color: #FF0000">FP076</span>
|      **[D.2]** <span style="color: #FF0000">FP044</span>
|      **[D.3]** <span style="color: #FF0000">FP089</span>
|      **[D.4]** <span style="color: #FF0000">FP193</span>
|      **[D.5]** <span style="color: #FF0000">FP112</span>
|
|
```{r section_1.6, warning=FALSE, message=FALSE}
##################################
# Consolidating all performance metrics
# for the numeric predictors
##################################
NumericPredictor_Metrics <- cbind(ROC_AUC_Summary$ROC_AUC,
                                  ATS_Summary$ATS,
                                  MIC_Summary$MIC,
                                  RV_Summary$RV)

colnames(NumericPredictor_Metrics) <- c("ROC_AUC",
                                        "ATS",
                                        "MIC",
                                        "RV")

rownames(NumericPredictor_Metrics) <- names(PMA_PreModelling_Train_Numeric)[2:ncol(PMA_PreModelling_Train_Numeric)]

NumericPredictor_Metrics <- as.data.frame(NumericPredictor_Metrics)

NumericPredictor_Metrics$Group <- ifelse(rownames(NumericPredictor_Metrics)=="MolWeight","MolWeight",
                                         ifelse(rownames(NumericPredictor_Metrics)=="NumCarbon","NumCarbon",
                                                ifelse(rownames(NumericPredictor_Metrics)=="NumMultBonds","NumMultBonds",
                                                       ifelse(rownames(NumericPredictor_Metrics)=="NumBonds","NumBonds",
                                                              ifelse(rownames(NumericPredictor_Metrics)=="NumRings","NumRings",
                                                                     "Others")))))

NumericPredictor_Metrics

splom(~NumericPredictor_Metrics[,c(1:4)],
      groups = NumericPredictor_Metrics$Group,
      pch = 16,
      cex = 2,
      alpha = 0.45,
      varnames = c("ROC_AUC", "ATS", "MIC", "RV"),
      auto.key = list(points = TRUE, space = "top"),
      main = "Feature Importance Comparison for Numeric Predictors",
      xlab = "Scatterplot Matrix of Feature Importance Metrics")

##################################
# Consolidating all performance metrics
# for the factor predictors
##################################
FET_P.Value_Plot <- xyplot(NegativeLog10_FET_P.Value ~ LogOddsRatio,
       groups = VP_F_Summary$Group,
       data = VP_F_Summary,
       xlab = "Log Odds Ratio",
       ylab = "-Log10(Fisher Exact Test P-Value)",
       type = "p",
       pch = 16,
       cex = 2,
       alpha = 0.45,
       auto.key = list(points = TRUE, space = "top"),
       main = "Feature Importance Comparison for Factor Predictors")

Gain_Plot <- xyplot(Gain ~ LogOddsRatio,
       groups = VP_G_Summary$Group,
       data = VP_G_Summary,
       xlab = "Log Odds Ratio",
       ylab = "Gain Ratio",
       type = "p",
       pch = 16,
       cex = 2,
       alpha = 0.45,
       auto.key = list(points = TRUE, space = "top"),
       main = "Feature Importance Comparison for Factor Predictors")

grid.arrange(FET_P.Value_Plot, 
             Gain_Plot, 
             ncol = 2) 

```

# **2. References**
|
| **[Book]** [Applied Predictive Modeling](http://appliedpredictivemodeling.com/) by Max Kuhn and Kjell Johnson
| **[Book]** [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani
| **[Book]** [Multivariate Data Visualization with R](http://lmdvr.r-forge.r-project.org/figures/figures.html) by Deepayan Sarkar
| **[Book]** [Machine Learning](https://bookdown.org/ssjackson300/Machine-Learning-Lecture-Notes/) by Samuel Jackson
| **[Book]** [Data Modeling Methods](https://bookdown.org/larget_jacob/data-modeling-methods/) by Jacob Larget
| **[Book]** [Introduction to R](https://biocorecrg.github.io/CRG_RIntroduction/) by Sara Bonnin
| **[R Package]** [AppliedPredictiveModeling](https://cran.r-project.org/web//packages/AppliedPredictiveModeling/AppliedPredictiveModeling.pdf) by Max Kuhn
| **[R Package]** [caret](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[R Package]** [rpart](https://mran.microsoft.com/web/packages/rpart/rpart.pdf) by Terry Therneau and Beth Atkinson
| **[R Package]** [lattice](https://cran.r-project.org/web/packages/lattice/lattice.pdf) by  Deepayan Sarkar
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html/) by Hadley Wickham
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [RANN](https://cran.r-project.org/web/packages/RANN/RANN.pdf) by  Sunil Arya, David Mount, Samuel Kemp and Gregory Jefferis
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [tidyverse](https://cran.r-project.org/web/packages/tidyverse/tidyverse.pdf) by Hadley Wickham
| **[R Package]** [lares](https://cran.rstudio.com/web/packages/lares/lares.pdf) by Bernardo Lares
| **[R Package]** [DMwR](https://mran.microsoft.com/snapshot/2016-05-02/web/packages/DMwR/DMwR.pdf) by Luis Torgo
| **[R Package]** [gridExtra](https://cran.r-project.org/web/packages/gridExtra/gridExtra.pdf) by Baptiste Auguie and Anton Antonov
| **[R Package]** [rattle](https://cran.r-project.org/web/packages/rattle/rattle.pdf) by Graham Williams
| **[R Package]** [rpart.plot](https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf) by Stephen Milborrow
| **[R Package]** [RColorBrewer](https://cran.r-project.org/web//packages/RColorBrewer/RColorBrewer.pdf) by Erich Neuwirth
| **[R Package]** [stats](https://search.r-project.org/R/refmans/stats/html/00Index.html) by R Core Team
| **[R Package]** [pls](https://cran.r-project.org/web/packages/pls/pls.pdf) by Kristian Hovde Liland
| **[R Package]** [nnet](https://cran.r-project.org/web/packages/nnet/nnet.pdf) by Brian Ripley
| **[R Package]** [elasticnet](https://cran.r-project.org/web/packages/elasticnet/elasticnet.pdf) by Hui Zou
| **[R Package]** [earth](https://cran.r-project.org/web/packages/earth/earth.pdf) by Stephen Milborrow
| **[R Package]** [party](https://cran.r-project.org/web/packages/party/party.pdf) by Torsten Hothorn
| **[R Package]** [kernlab](https://cran.r-project.org/web/packages/kernlab/kernlab.pdf) by Alexandros Karatzoglou
| **[R Package]** [randomForest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf) by Andy Liaw
| **[R Package]** [Cubist](https://cran.r-project.org/web/packages/Cubist/Cubist.pdf) by Max Kuhn
| **[R Package]** [minerva](https://cran.r-project.org/web/packages/minerva/minerva.pdf) by Michele Filosi
| **[R Package]** [CORElearn](https://cran.r-project.org/web/packages/CORElearn/CORElearn.pdf) by Marko Robnik-Sikonja and Petr Savicky
| **[Article]** [The caret Package](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[Article]** [A Short Introduction to the caret Package](https://cran.r-project.org/web/packages/caret/vignettes/caret.html) by Max Kuhn
| **[Article]** [Caret Package – A Practical Guide to Machine Learning in R](https://www.machinelearningplus.com/machine-learning/caret-package/#:~:text=Caret%20is%20short%20for%20Classification%20And%20REgression%20Training.,track%20of%20which%20algorithm%20resides%20in%20which%20package.) by Selva Prabhakaran
| **[Article]** [Tuning Machine Learning Models Using the Caret R Package](https://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/) by Jason Brownlee
| **[Article]** [Lattice Graphs](http://www.sthda.com/english/wiki/lattice-graphs) by STHDA Team
| **[Article]** [A Tour of Machine Learning Algorithms](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/) by Jason Brownlee
| **[Article]** [Maximal Information Coefficient](https://www.r-bloggers.com/2014/09/maximal-information-coefficient-part-ii/) by R Bloggers Team
| **[Article]** [Understanding t-Tests: 1-sample, 2-sample, and Paired t-Tests](https://blog.minitab.com/en/adventures-in-statistics-2/understanding-t-tests-1-sample-2-sample-and-paired-t-tests) by Minitab Support Team
| **[Article]** [How to Interpret a ROC Curve (With Examples)](https://www.statology.org/interpret-roc-curve/) by Statology Team
| **[Article]** [Fisher’s Exact Test](https://www.statstest.com/fischers-exact-test/) by Stats Test Team
| **[Article]** [Visualization of Volcano Plots in R](https://sdgamboa.github.io/post/2020_volcano/) by Samuel David Gamboa-Tuz
| **[Article]** [Using Volcano Plots in R to Visualize Microarray and RNA-seq Results](https://www.r-bloggers.com/2014/05/using-volcano-plots-in-r-to-visualize-microarray-and-rna-seq-results/) by Stephen Turner
| **[Publication]** [ Signal Detection Theory and ROC Analysis](https://www.semanticscholar.org/paper/Signal-detection-theory-and-ROC-analysis-Egan/a2cf3479c3b5c96b8ee8c353876fba5048a39fb7) by J Egan ( Series in
Cognition and Perception)
| **[Publication]** [Detecting Novel Associations in Large Data Sets](https://www.science.org/doi/10.1126/science.1205438) by David Reshef, Yakir Reshef, Hilary Finucane, Sharon Grossman, Gilean Mcvean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher and Pardis Sabeti (Science)
| **[Publication]** [Theoretical and Empirical Analysis of ReliefF and RReliefF](https://link.springer.com/article/10.1023/A:1025667309714) by Marko Robnik-Šikonja and Igor Kononenko (Machine Learning)
| **[Publication]** [First (?) Occurrence of Common Terms in Probability and Statistics-A Second List, with Corrections](https://www.jstor.org/stable/2685564?seq=1#page_scan_tab_contents) by H David (The American Statistician)
| **[Course]** [Applied Data Mining and Statistical Learning](https://online.stat.psu.edu/stat508/) by Penn State Eberly College of Science
| **[Course]** [Regression Methods](https://online.stat.psu.edu/stat501/) by Penn State Eberly College of Science
| **[Course]** [Applied Regression Analysis](https://online.stat.psu.edu/stat462/) by Penn State Eberly College of Science
|
|
|
|